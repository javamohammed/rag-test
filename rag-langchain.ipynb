{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6f92da7",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef5dcac",
   "metadata": {},
   "source": [
    "# Installing & Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "479c9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insalling libraries\n",
    "!pip install -q -U \\\n",
    "  langchain \\\n",
    "  langchain-core \\\n",
    "  langchain-community \\\n",
    "  langchain-openai \\\n",
    "  langchain-text-splitters \\\n",
    "  chromadb \\\n",
    "  gradio \\\n",
    "  python-dotenv \\\n",
    "  tiktoken \\\n",
    "  openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4345ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ OPENAI_API_KEY. ØªØ£ÙƒØ¯ Ø£Ù†Ùƒ ÙˆØ¶Ø¹ØªÙ‡ ÙÙŠ .env Ø£Ùˆ ÙÙŠ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb965f",
   "metadata": {},
   "source": [
    "# Loading & Splitting Data (Chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f08a24dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/rag-test/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b7e9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹: 4\n",
      "Ù…Ø«Ø§Ù„ Ù…Ù‚Ø·Ø¹:\n",
      " ğŸª Ù…Ø¹Ø±Ø¶ Ù„ÙˆØ§Ø²Ù… Ù„Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ù†Ø²Ù„ÙŠØ© ÙˆØ§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©\n",
      "\n",
      "ğŸ”¹ Ø§Ù„Ù†Ø´Ø£Ø©:\n",
      "ØªØ£Ø³Ø³Øª Ø´Ø±ÙƒØ© Ù„ÙˆØ§Ø²Ù… ÙÙŠ Ø¹Ø§Ù… 2023 ÙÙŠ Ù…Ø¯ÙŠÙ†Ø© Ø£Ø³ÙŠÙˆØ·ØŒ Ù…ØµØ±. Ø¨Ø¯Ø£Øª Ø¨ÙØ±Ø¹ ØµØºÙŠØ± ÙÙŠ ÙˆØ³Ø· Ø§Ù„Ø¨Ù„Ø¯ØŒ ÙˆÙ…Ø¹ Ù…Ø±ÙˆØ± Ø§Ù„ÙˆÙ‚Øª ØªÙˆØ³Ø¹Øª Ù„ØªØµØ¨Ø­ ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø£Ø¨Ø±Ø² Ù…Ø¹Ø§Ø±Ø¶ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ù†Ø²Ù„ÙŠØ© ÙÙŠ ØµØ¹ÙŠØ¯ Ù…ØµØ±.\n",
      "\n",
      "ğŸ”¹ Ø§Ù„Ù…Ù‚Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ:\n",
      "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Ø´ Ø³ÙŠØªÙŠØŒ Ø£Ø³ÙŠÙˆØ·ØŒ Ù…ØµØ±.\n",
      "Ø§Ù„Ù‡Ø§ØªÙ: +201033103539\n",
      "Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ± ...\n"
     ]
    }
   ],
   "source": [
    "DATA_FILE_PATH = \"lawazem-info.txt\"   # Ø¹Ø¯Ù‘Ù„Ù‡ Ø¥Ø°Ø§ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù…Ø®ØªÙ„Ù\n",
    "PERSIST_DIR = \"chroma_db\"            # Ù„ØªØ®Ø²ÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Chroma Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø±Øµ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„ÙƒÙ†Ù‡ Ù…ÙÙŠØ¯)\n",
    "\n",
    "# 1) Load\n",
    "loader = TextLoader(DATA_FILE_PATH, encoding=\"utf-8\")\n",
    "raw_docs = loader.load()\n",
    "\n",
    "# 2) Split\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=80,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"â€”\", \"-\", \"â€¢\", \".\", \"ØŸ\", \"!\", \"ØŒ\", \" \"],\n",
    ")\n",
    "docs = splitter.split_documents(raw_docs)\n",
    "\n",
    "print(\"Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹:\", len(docs))\n",
    "print(\"Ù…Ø«Ø§Ù„ Ù…Ù‚Ø·Ø¹:\\n\", docs[0].page_content[:300], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "709e3dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù€ retriever\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡/ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Chroma\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=PERSIST_DIR\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "print(\"âœ… ØªÙ… ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù€ retriever\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d89eb",
   "metadata": {},
   "source": [
    "# Testing the Retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "797c42a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=\"gpt-4o-mini\",   # ØºÙŠÙ‘Ø±Ù‡Ø§ Ø¥Ø°Ø§ ØªØ±ÙŠØ¯ Ù†Ù…ÙˆØ°Ø¬ Ø¢Ø®Ø±\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨ÙŠØ¹Ø§Øª Ù„Ù…ØªØ¬Ø±.\n",
    "Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ¨Ø§Ø®ØªØµØ§Ø± ÙˆÙˆØ¶ÙˆØ­ Ø§Ø¹ØªÙ…Ø§Ø¯Ù‹Ø§ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ§Ù„ÙŠ.\n",
    "Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ØŒ Ù‚Ù„: \"Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø© ÙƒØ§ÙÙŠØ© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©.\"\n",
    "\n",
    "Ø§Ù„Ø³ÙŠØ§Ù‚:\n",
    "{context}\n",
    "\n",
    "Ø§Ù„Ø³Ø¤Ø§Ù„:\n",
    "{question}\n",
    "\n",
    "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:\"\"\"\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ø³ÙŠØ§Ù‚\n",
    "    return \"\\n\\n\".join([f\"- {d.page_content.strip()}\" for d in docs])\n",
    "\n",
    "# Ù‡Ø°Ø§ Ø§Ù„Ù€ chain ÙŠØ£Ø®Ø° Ø³Ø¤Ø§Ù„ (string) ÙˆÙŠØ±Ø¬Ø¹ Ø¬ÙˆØ§Ø¨ (string)\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(format_docs),\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b58e7",
   "metadata": {},
   "source": [
    "# Building & Testing RAG using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae180d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:\n",
      " Ù†Ø¹Ù…ØŒ Ù„Ø¯ÙŠÙ†Ø§ ÙƒØ§ØªÙ„ ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ Ø³Ø¹Ø© 1.7 Ù„ØªØ± Ø¨Ø³Ø¹Ø± 850 Ø¬Ù†ÙŠÙ‡ Ù…ØµØ±ÙŠ.\n",
      "\n",
      "Ø§Ù„Ù…ØµØ§Ø¯Ø±:\n",
      " lawazem-info.txt\n",
      "\n",
      "Ù…Ù‚Ø§Ø·Ø¹ Ù…Ø³ØªØ®Ø¯Ù…Ø©:\n",
      " [1] ğŸ”¹ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª:\n",
      "- Ø£Ø·Ù‚Ù… Ø¹Ø´Ø§Ø¡ Ø¨ÙˆØ±Ø³Ù„ÙŠÙ† (18 Ù‚Ø·Ø¹Ø©): Ø³Ø¹Ø±Ù‡Ø§ ÙŠØ¨Ø¯Ø£ Ù…Ù† 1500 Ø¬Ù†ÙŠÙ‡ Ù…ØµØ±ÙŠ.\n",
      "- Ø£ÙˆØ§Ù†ÙŠ Ø·Ù‡ÙŠ Ø³ØªØ§Ù†Ù„Ø³ Ø³ØªÙŠÙ„ (Ø·Ù‚Ù… 10 Ù‚Ø·Ø¹): Ø§Ù„Ø³Ø¹Ø± Ø­ÙˆØ§Ù„ÙŠ 2200 Ø¬Ù†ÙŠÙ‡ Ù…ØµØ±ÙŠ.\n",
      "- ÙƒØ§ØªÙ„ ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ 1.7 Ù„ØªØ±: Ø³Ø¹Ø±Ù‡ 850 Ø¬Ù†ÙŠÙ‡ Ù…ØµØ±ÙŠ.\n",
      "- Ø®Ù„Ø§Ø· ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ 600 ÙˆØ§Øª Ù…Ø¹ Ù…Ø·Ø­Ù†Ø©: Ø§Ù„Ø³Ø¹...\n",
      "\n",
      "[2] - Ø·Ø§Ø³Ø© ØªÙŠÙØ§Ù„ 28 Ø³Ù…: Ø§Ù„Ø³Ø¹Ø± 750 Ø¬Ù†ÙŠÙ‡ Ù…ØµØ±ÙŠ.\n",
      "- Ø³Ø®Ø§Ù† Ù…ÙŠØ§Ù‡ ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ 50 Ù„ØªØ±: Ø§Ù„Ø³Ø¹Ø± 3700 Ø¬Ù†ÙŠÙ‡ Ù…ØµØ±ÙŠ....\n",
      "\n",
      "[3] ğŸ”¹ Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø§Ø³ØªØ¨Ø¯Ø§Ù„ ÙˆØ§Ù„Ø¥Ø±Ø¬Ø§Ø¹:\n",
      "- ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø£Ùˆ Ø¥Ø±Ø¬Ø§Ø¹Ù‡Ø§ Ø®Ù„Ø§Ù„ 14 ÙŠÙˆÙ… Ù…Ù† ØªØ§Ø±ÙŠØ® Ø§Ù„Ø´Ø±Ø§Ø¡ Ù…Ø¹ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„ÙØ§ØªÙˆØ±Ø©.\n",
      "- Ø§Ù„Ø¶Ù…Ø§Ù† ÙŠØ´Ù…Ù„ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ù…Ù† Ø³Ù†Ø© Ø¥Ù„Ù‰ Ø«Ù„Ø§Ø« Ø³Ù†ÙˆØ§Øª Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†ØªØ¬.\n",
      "\n",
      "ğŸ”¹ Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø¹Ù…Ù„:\n",
      "- Ø§Ù„Ø³Ø¨Øª â€“ Ø§Ù„Ø®Ù…ÙŠØ³: 1...\n",
      "\n",
      "[4] ğŸª Ù…Ø¹Ø±Ø¶ Ù„ÙˆØ§Ø²Ù… Ù„Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ù†Ø²Ù„ÙŠØ© ÙˆØ§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©\n",
      "\n",
      "ğŸ”¹ Ø§Ù„Ù†Ø´Ø£Ø©:\n",
      "ØªØ£Ø³Ø³Øª Ø´Ø±ÙƒØ© Ù„ÙˆØ§Ø²Ù… ÙÙŠ Ø¹Ø§Ù… 2023 ÙÙŠ Ù…Ø¯ÙŠÙ†Ø© Ø£Ø³ÙŠÙˆØ·ØŒ Ù…ØµØ±. Ø¨Ø¯Ø£Øª Ø¨ÙØ±Ø¹ ØµØºÙŠØ± ÙÙŠ ÙˆØ³Ø· Ø§Ù„Ø¨Ù„Ø¯ØŒ ÙˆÙ…Ø¹ Ù…Ø±ÙˆØ± Ø§Ù„ÙˆÙ‚Øª ØªÙˆØ³Ø¹Øª Ù„ØªØµØ¨Ø­ ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø£Ø¨Ø±Ø² Ù…Ø¹Ø§Ø±Ø¶ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ù†Ø²Ù„ÙŠØ© ÙÙŠ ØµØ¹ÙŠØ¯ Ù…ØµØ±.\n",
      "\n",
      "ğŸ”¹...\n"
     ]
    }
   ],
   "source": [
    "def ask_with_sources(question: str):\n",
    "    # Ù†Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø­ØªÙ‰ Ù†Ø¹Ø±Ø¶ Ø§Ù„Ù…ØµØ§Ø¯Ø±\n",
    "    if hasattr(retriever, \"invoke\"):\n",
    "        source_docs = retriever.invoke(question)\n",
    "    else:\n",
    "        source_docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "    answer = rag_chain.invoke(question)\n",
    "\n",
    "    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ØµØ§Ø¯Ø± (Ø¥Ù† ÙˆØ¬Ø¯Øª)\n",
    "    sources = []\n",
    "    for d in source_docs:\n",
    "        src = d.metadata.get(\"source\")\n",
    "        if src and src not in sources:\n",
    "            sources.append(src)\n",
    "\n",
    "    # Ø³Ù†ÙŠØ¨ØªØ³ Ù‚ØµÙŠØ±Ø© Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©\n",
    "    snippets = []\n",
    "    for i, d in enumerate(source_docs[:4], start=1):\n",
    "        snippets.append(f\"[{i}] {d.page_content[:220].strip()}...\")\n",
    "\n",
    "    return answer, (\"\\n\".join(sources) if sources else \"Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ØµØ§Ø¯Ø± (metadata) ÙˆØ§Ø¶Ø­Ø©.\"), \"\\n\\n\".join(snippets)\n",
    "\n",
    "\n",
    "# Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹\n",
    "ans, srcs, snips = ask_with_sources(\"Ø¹Ù†Ø¯ÙƒÙ… ÙƒØ§ØªÙ„ ÙƒÙ‡Ø±Ø¨Ø§Ø¡ØŸ\")\n",
    "print(\"Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:\\n\", ans)\n",
    "print(\"\\nØ§Ù„Ù…ØµØ§Ø¯Ø±:\\n\", srcs)\n",
    "print(\"\\nÙ…Ù‚Ø§Ø·Ø¹ Ù…Ø³ØªØ®Ø¯Ù…Ø©:\\n\", snips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e1171ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
      "\n",
      "An error occurred while running the chain: Error code: 404 - {'error': {'message': 'This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "chain_test_query = \"Ø¹Ù†Ø¯ÙƒÙ… ÙƒØ§ØªÙ„ ÙƒÙ‡Ø±Ø¨Ø§Ø¡ØŸ\"\n",
    "try:\n",
    "    result = qa_chain.invoke({\"question\": chain_test_query})\n",
    "\n",
    "    # Print the answer and sources from the result dictionary\n",
    "    print(\"\\n--- Answer ---\")\n",
    "    print(result.get(\"answer\", \"No answer generated.\"))\n",
    "\n",
    "    print(\"\\n--- Sources ---\")\n",
    "    print(result.get(\"sources\", \"No sources identified.\"))\n",
    "\n",
    "    # Optionally print snippets from the source documents returned\n",
    "    if \"source_documents\" in result:\n",
    "        print(\"\\n--- Source Document Snippets ---\")\n",
    "        for i, doc in enumerate(result[\"source_documents\"]):\n",
    "            content_snippet = doc.page_content[:250].strip()\n",
    "            print(f\"Doc {i+1}: {content_snippet}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred while running the chain: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb788c4e",
   "metadata": {},
   "source": [
    "# Building Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4074b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://e8b24a5de5a6f077f2.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e8b24a5de5a6f077f2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def gradio_chat(user_question):\n",
    "    if not user_question.strip():\n",
    "        return \"Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø£ÙˆÙ„Ø§Ù‹.\", \"\", \"\"\n",
    "\n",
    "    answer, sources, snippets = ask_with_sources(user_question)\n",
    "    return answer, sources, snippets\n",
    "\n",
    "ui = gr.Interface(\n",
    "    fn=gradio_chat,\n",
    "    inputs=gr.Textbox(label=\"Ø³Ø¤Ø§Ù„Ùƒ\", placeholder=\"Ù…Ø«Ø§Ù„: Ù‡Ù„ Ø¹Ù†Ø¯ÙƒÙ… ÙƒØ§ØªÙ„ ÙƒÙ‡Ø±Ø¨Ø§Ø¡ØŸ\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©\"),\n",
    "        gr.Textbox(label=\"Ø§Ù„Ù…ØµØ§Ø¯Ø±\"),\n",
    "        gr.Textbox(label=\"Ù…Ù‚Ø§Ø·Ø¹ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù„Ù„ØªØ£ÙƒØ¯)\")\n",
    "    ],\n",
    "    title=\"RAG + Chroma + OpenAI (Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ LangChain 1.x Ø¨Ø¯ÙˆÙ† chains)\",\n",
    "    description=\"ÙŠØ³Ø­Ø¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Ù…Ù„Ù Ø§Ù„Ù†Øµ ÙÙ‚Ø· ÙˆÙŠØ¹Ø±Ø¶ Ù…ØµØ§Ø¯Ø±/Ù…Ù‚Ø§Ø·Ø¹ Ø¯Ø§Ø¹Ù…Ø©.\"\n",
    ")\n",
    "\n",
    "ui.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
